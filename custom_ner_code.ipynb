{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#fc0366;\">***Adding Custom Named Entity***</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***_Creating custom Named Entity Recognition label to recognize numbers and snacks_***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _***Labeling the Snacks and also Numbers in Words:***_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 390.8430703919304}\n",
      "{'ner': 56.42796152513488}\n",
      "{'ner': 24.80943665463964}\n",
      "{'ner': 24.7181492887833}\n",
      "{'ner': 18.494845443326927}\n",
      "{'ner': 19.938373204503435}\n",
      "{'ner': 8.453840365540383e-06}\n",
      "{'ner': 24.588350510273678}\n",
      "{'ner': 2.1177412018563198}\n",
      "{'ner': 17.265217750330777}\n",
      "{'ner': 25.99001882712966}\n",
      "{'ner': 1.614956006840486}\n",
      "{'ner': 24.70626041737949}\n",
      "{'ner': 13.291933010586488}\n",
      "{'ner': 4.232428059943727}\n",
      "{'ner': 3.317283206188521e-08}\n",
      "{'ner': 38.37958051782777}\n",
      "{'ner': 6.002458701486143}\n",
      "{'ner': 1.2395844585745761e-08}\n",
      "{'ner': 12.49730104460509}\n",
      "Entities in 'I'd like to have onion samosa for breakfast.'\n",
      "SNACKS  --  onion samosa\n",
      "Entities in 'How about having gobi chilli as a snack?'\n",
      "SNACKS  --  gobi chilli\n",
      "Entities in 'Have you tried masala bonda before?'\n",
      "SNACKS  --  masala bonda\n",
      "Entities in 'Let's order some veg puff.'\n",
      "SNACKS  --  veg puff\n",
      "Entities in 'My favorite snack is rusk.'\n",
      "SNACKS  --  rusk\n",
      "Entities in 'Could you get me chicken roll from the bakery?'\n",
      "SNACKS  --  chicken roll\n",
      "Entities in 'Chicken puff would be perfect for tea time.'\n",
      "SNACKS  --  Chicken puff\n",
      "Entities in 'There's nothing better than bread omelette on a rainy day.'\n",
      "SNACKS  --  bread omelette\n",
      "Entities in 'I'm craving curd vada right now.'\n",
      "SNACKS  --  curd vada\n",
      "Entities in 'Bajji is a popular street food.'\n",
      "SNACKS  --  Bajji\n",
      "Entities in 'I need five samosas.'\n",
      "NUMBERS  --  five\n",
      "SNACKS  --  samosas\n"
     ]
    }
   ],
   "source": [
    "#Import Dependencies\n",
    "import random\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "LABEL_NUMBERS = 'NUMBERS'\n",
    "LABEL_SNACKS = 'SNACKS'\n",
    "TRAIN_DATA = []\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "snacks_list = ['bajji', 'bread omelette', 'chicken puff', 'chicken roll', 'curd vada', 'egg puff', 'gobi chilli', 'masala bonda', 'masala vada', 'mushroom chilli', 'onion bonda', 'onion samosa', 'potato samosa', 'rusk', 'salt biscuit', 'sambar vada', 'veg puff', 'veg roll', 'bajjis', 'bread omelettes', 'chicken puffs', 'chicken rolls', 'curd vadas', 'egg puffs', 'gobi chillis', 'masala bondas', 'masala vadas', 'mushroom chillis', 'onion bondas', 'onion samosas', 'potato samosas', 'rusks', 'salt biscuits', 'sambar vadas', 'veg puffs', 'veg rolls']\n",
    "number_word_list = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', \n",
    "                      'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen',\n",
    "                      'nineteen', 'twenty', 'twenty one', 'twenty two', 'twenty three', 'twenty four', 'twenty five', \n",
    "                      'twenty six', 'twenty seven', 'twenty eight', 'twenty nine', 'thirty', 'thirty one', 'thirty two', 'thirty three', 'thirty four', 'thirty five', 'thirty six', 'thirty seven', 'thirty eight', 'thirty nine', 'forty', 'forty one', 'forty two', 'forty three', 'forty four', 'forty five', 'forty six', 'forty seven', 'forty eight', 'forty nine', 'fifty', 'fifty one', 'fifty two', 'fifty three', 'fifty four', 'fifty five', 'fifty six', 'fifty seven', 'fifty eight', 'fifty nine', 'sixty',\n",
    "                      'sixty one', 'sixty two', 'sixty three', 'sixty four', 'sixty five', 'sixty six', 'sixty seven', 'sixty eight', 'sixty nine', 'seventy', 'seventy one', 'seventy two', 'seventy three', 'seventy four', \n",
    "                      'seventy five', 'seventy six', 'seventy seven', 'seventy eight', 'seventy nine', 'eighty', 'eighty one', 'eighty two', 'eighty three', 'eighty four', 'eighty five', 'eighty six', 'eighty seven', 'eighty eight', 'eighty nine', 'ninety', 'ninety one', 'ninety two', 'ninety three', 'ninety four', 'ninety five', 'ninety six', 'ninety seven', 'ninety eight', 'ninety nine', 'one hundred']\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "for number_word in number_word_list:\n",
    "    for snack in snacks_list:\n",
    "        sentence = f\"I'd like to have {number_word} {snack} for breakfast.\"\n",
    "        start_idx = sentence.index(number_word)\n",
    "        end_idx = start_idx + len(number_word)\n",
    "        start_idx_snack = sentence.index(snack)\n",
    "        end_idx_snack = start_idx_snack + len(snack)\n",
    "        TRAIN_DATA.append((sentence, {'entities': [(start_idx, end_idx, LABEL_NUMBERS), (start_idx_snack, end_idx_snack, LABEL_SNACKS)]}))\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "for snack in snacks_list:\n",
    "    for sentence_pattern in [\"I'd like to have {snack} for breakfast.\",\n",
    "                             \"How about having {snack} as a snack?\",\n",
    "                             \"Have you tried {snack} before?\",\n",
    "                             \"Let's order some {snack}.\",\n",
    "                             \"My favorite snack is {snack}.\",\n",
    "                             \"Could you get me {snack} from the bakery?\",\n",
    "                             \"{snack} would be perfect for tea time.\",\n",
    "                             \"There's nothing better than {snack} on a rainy day.\",\n",
    "                             \"I'm craving {snack} right now.\",\n",
    "                             \"{snack} is a popular street food.\"]:\n",
    "        sentence = sentence_pattern.format(snack=snack)\n",
    "        start_idx = sentence.index(snack)\n",
    "        end_idx = start_idx + len(snack)\n",
    "        TRAIN_DATA.append((sentence, {'entities': [(start_idx, end_idx, LABEL_SNACKS)]}))\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "#Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "ner = nlp.get_pipe('ner')\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "#Add labels\n",
    "ner.add_label(LABEL_SNACKS)\n",
    "ner.add_label(LABEL_NUMBERS)\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "#Training the model\n",
    "optimizer = nlp.create_optimizer()\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    for itn in range(20):  # Training for 20 iterations\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            nlp.update([example], drop=0.35, sgd=optimizer, losses=losses)\n",
    "        print(losses)\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "# Test the trained model\n",
    "test_sentences = [\n",
    "    \"I'd like to have onion samosa for breakfast.\",\n",
    "    \"How about having gobi chilli as a snack?\",\n",
    "    \"Have you tried masala bonda before?\",\n",
    "    \"Let's order some veg puff.\",\n",
    "    \"My favorite snack is rusk.\",\n",
    "    \"Could you get me chicken roll from the bakery?\",\n",
    "    \"Chicken puff would be perfect for tea time.\",\n",
    "    \"There's nothing better than bread omelette on a rainy day.\",\n",
    "    \"I'm craving curd vada right now.\",\n",
    "    \"Bajji is a popular street food.\",\n",
    "    \"I need five samosas.\"\n",
    "]\n",
    "\n",
    "for test_sentence in test_sentences:\n",
    "    doc = nlp(test_sentence)\n",
    "    print(\"Entities in '%s'\" % test_sentence)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.label_, \" -- \", ent.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBERS  --  5\n",
      "SNACKS  --  bajji\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['bajji'], ['5'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_snacks_list=[]\n",
    "orderded_snack_quantity_list=[]\n",
    "doc = nlp(\"I'd like to have 5 bajji for breakfast.\")\n",
    "for ent in doc.ents:\n",
    "     if ent.text in snacks_list:\n",
    "          ordered_snacks_list.append(ent.text)\n",
    "     if ent.text in number_word_list or ent.text in [str(i) for i in range(1,101)]:\n",
    "           orderded_snack_quantity_list.append(ent.text)\n",
    "     print(ent.label_, \" -- \", ent.text)\n",
    "ordered_snacks_list,orderded_snack_quantity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the trained model\n",
    "nlp.to_disk(\"custom_ner_model_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _***Checking for NER Prediction***:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBERS  --  five\n",
      "SNACKS  --  onion samosa\n",
      "NUMBERS  --  fifty\n",
      "SNACKS  --  egg puffs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['onion samosa', 'egg puffs'], ['five', 'fifty'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_snacks_list=[]\n",
    "orderded_snack_quantity_list=[]\n",
    "doc = nlp(\"i need five onion samosa and fifty egg puffs\")\n",
    "for ent in doc.ents:\n",
    "     if ent.text in snacks_list:\n",
    "          ordered_snacks_list.append(ent.text)\n",
    "     if ent.text in number_word_list :\n",
    "          orderded_snack_quantity_list.append(ent.text)\n",
    "     print(ent.label_, \" -- \", ent.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _***Labeling the Numbers in Digits***_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 2.871892488761431}\n",
      "{'ner': 3.554241015687403e-10}\n",
      "{'ner': 3.287615662521418e-09}\n",
      "{'ner': 4.322149727064123e-12}\n",
      "{'ner': 3.121569692195033e-12}\n",
      "{'ner': 1.4156577658815673e-14}\n",
      "{'ner': 1.4790945404200627e-14}\n",
      "{'ner': 1.0138945868715594e-13}\n",
      "{'ner': 4.300881413210416e-16}\n",
      "{'ner': 4.205981359815786e-13}\n",
      "{'ner': 1.8907915403814624e-14}\n",
      "{'ner': 2.0349489453143382e-16}\n",
      "{'ner': 1.1182474878588864e-14}\n",
      "{'ner': 1.2367822385533122e-16}\n",
      "{'ner': 7.885815031540843e-15}\n",
      "{'ner': 3.902037279566051e-15}\n",
      "{'ner': 3.6594658573354995e-15}\n",
      "{'ner': 1.4089672099317641e-15}\n",
      "{'ner': 3.2888432480180227e-15}\n",
      "{'ner': 1.4461573235718025e-15}\n",
      "Entities in 'I need 5 samosas and 1 chicken puff'\n",
      "NUMBERS  --  5\n",
      "SNACKS  --  samosas\n",
      "NUMBERS  --  1\n",
      "SNACKS  --  chicken puff\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "LABEL_NUMBERS = 'NUMBERS'\n",
    "LABEL_SNACKS = 'SNACKS'\n",
    "TRAIN_DATA = []\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "snacks_list = ['bajji', 'bread omelette', 'chicken puff', 'chicken roll', 'curd vada', 'egg puff', 'gobi chilli', 'masala bonda', 'masala vada', 'mushroom chilli', 'onion bonda', 'onion samosa', 'potato samosa', 'rusk', 'salt biscuit', 'sambar vada', 'veg puff', 'veg roll', 'bajjis', 'bread omelettes', 'chicken puffs', 'chicken rolls', 'curd vadas', 'egg puffs', 'gobi chillis', 'masala bondas', 'masala vadas', 'mushroom chillis', 'onion bondas', 'onion samosas', 'potato samosas', 'rusks', 'salt biscuits', 'sambar vadas', 'veg puffs', 'veg rolls']\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "for number in range(1,101):\n",
    "    number=str(number)\n",
    "    for snack in snacks_list:\n",
    "        sentence = f\"I'd like to have {number} {snack} for breakfast.\"\n",
    "        start_idx = sentence.index(number)\n",
    "        end_idx = start_idx + len(number)\n",
    "        start_idx_snack = sentence.index(snack)\n",
    "        end_idx_snack = start_idx_snack + len(snack)\n",
    "        TRAIN_DATA.append((sentence, {'entities': [(start_idx, end_idx, LABEL_NUMBERS), (start_idx_snack, end_idx_snack, LABEL_SNACKS)]}))\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "nlp2 = spacy.load('custom_ner_model_1')\n",
    "ner = nlp2.get_pipe('ner')\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "ner.add_label(LABEL_SNACKS)\n",
    "ner.add_label(LABEL_NUMBERS)\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "optimizer = nlp2.create_optimizer()\n",
    "other_pipes = [pipe for pipe in nlp2.pipe_names if pipe != \"ner\"]\n",
    "with nlp2.disable_pipes(*other_pipes):\n",
    "    for itn in range(20):  # Training for 20 iterations\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            doc = nlp2.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            nlp2.update([example], drop=0.35, sgd=optimizer, losses=losses)\n",
    "        print(losses)\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "test_sentences = [\n",
    "                  \"I need 5 samosas and 1 chicken puff\"\n",
    "                 ]\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "for test_sentence in test_sentences:\n",
    "    doc = nlp2(test_sentence)\n",
    "    print(\"Entities in '%s'\" % test_sentence)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.label_, \" -- \", ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the trained model\n",
    "nlp2.to_disk(\"custom_ner_model_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _***Checking for NER Prediction***:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBERS -- 100\n",
      "SNACKS -- bajjis\n",
      "NUMBERS -- seventy two\n",
      "SNACKS -- egg puff\n",
      "Ordered Snacks: ['bajjis', 'egg puff']\n",
      "Ordered Snack Quantities: ['100', 'seventy two']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "ordered_snacks_list = []\n",
    "ordered_snack_quantity_list = []\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "#loading the saved Model\n",
    "model=spacy.load(\"custom_ner_model_1\")\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "doc = model((\"I'd like to have 100 bajjis and  seventy two egg puff for breakfast.\").lower())\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"SNACKS\":\n",
    "        ordered_snacks_list.append(ent.text)\n",
    "    if ent.label_ == \"NUMBERS\":\n",
    "        ordered_snack_quantity_list.append(ent.text)\n",
    "    # if ent.label_ == \"CARDINAL\":\n",
    "    #     ordered_snack_quantity_list.append(ent.text)\n",
    "    print(ent.label_, \"--\", ent.text)\n",
    "\n",
    "print(\"Ordered Snacks:\", ordered_snacks_list)\n",
    "print(\"Ordered Snack Quantities:\", ordered_snack_quantity_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
